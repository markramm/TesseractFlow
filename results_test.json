{
  "experiment_id": "openrouter_test-20251026T052642",
  "config": {
    "name": "openrouter_test",
    "workflow": "code_review",
    "variables": [
      {
        "name": "temperature",
        "level_1": 0.3,
        "level_2": 0.7
      },
      {
        "name": "model",
        "level_1": "openrouter/openai/gpt-4o-mini",
        "level_2": "openrouter/anthropic/claude-3.5-sonnet"
      },
      {
        "name": "context_size",
        "level_1": "file_only",
        "level_2": "full_module"
      },
      {
        "name": "generation_strategy",
        "level_1": "standard",
        "level_2": "chain_of_thought"
      }
    ],
    "utility_weights": {
      "quality": 1.0,
      "cost": 0.1,
      "time": 0.05
    },
    "workflow_config": {
      "rubric": {
        "clarity": {
          "description": "Is the review easy to follow and understand?",
          "scale": "1-10"
        },
        "accuracy": {
          "description": "Do the identified issues reflect real problems?",
          "scale": "1-10"
        },
        "completeness": {
          "description": "Does the review cover important aspects of the code?",
          "scale": "1-10"
        }
      },
      "sample_code_path": "tesseract_flow/evaluation/rubric.py",
      "language": "python",
      "context_descriptions": {
        "file_only": "Review limited to the provided snippet.",
        "full_module": "Consider module-level implications during review."
      }
    }
  },
  "test_configurations": [
    {
      "test_number": 1,
      "config_values": {
        "temperature": 0.3,
        "model": "openrouter/openai/gpt-4o-mini",
        "context_size": "file_only",
        "generation_strategy": "standard"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 2,
      "config_values": {
        "temperature": 0.3,
        "model": "openrouter/openai/gpt-4o-mini",
        "context_size": "file_only",
        "generation_strategy": "chain_of_thought"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 3,
      "config_values": {
        "temperature": 0.3,
        "model": "openrouter/anthropic/claude-3.5-sonnet",
        "context_size": "full_module",
        "generation_strategy": "standard"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 4,
      "config_values": {
        "temperature": 0.3,
        "model": "openrouter/anthropic/claude-3.5-sonnet",
        "context_size": "full_module",
        "generation_strategy": "chain_of_thought"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 5,
      "config_values": {
        "temperature": 0.7,
        "model": "openrouter/openai/gpt-4o-mini",
        "context_size": "full_module",
        "generation_strategy": "standard"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 6,
      "config_values": {
        "temperature": 0.7,
        "model": "openrouter/openai/gpt-4o-mini",
        "context_size": "full_module",
        "generation_strategy": "chain_of_thought"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 7,
      "config_values": {
        "temperature": 0.7,
        "model": "openrouter/anthropic/claude-3.5-sonnet",
        "context_size": "file_only",
        "generation_strategy": "standard"
      },
      "workflow": "code_review"
    },
    {
      "test_number": 8,
      "config_values": {
        "temperature": 0.7,
        "model": "openrouter/anthropic/claude-3.5-sonnet",
        "context_size": "file_only",
        "generation_strategy": "chain_of_thought"
      },
      "workflow": "code_review"
    }
  ],
  "results": [],
  "status": "FAILED",
  "started_at": "2025-10-26T05:26:42.558878Z",
  "error": "LLM evaluation request failed after 3 attempts.",
  "experiment_metadata": {
    "config_hash": "d19780d3524cc831ec96ab5e1df29ff792a42e38ff7e0ef18d8143163352c1ce",
    "created_at": "2025-10-26T05:26:42.558733Z",
    "dependencies": {
      "pydantic": "2.12.3",
      "langgraph": "1.0.1",
      "litellm": "1.79.0"
    },
    "non_deterministic_sources": [
      "llm_sampling"
    ]
  },
  "metadata": {},
  "baseline_test_number": 1,
  "baseline_config": {
    "test_number": 1,
    "config_values": {
      "temperature": 0.3,
      "model": "openrouter/openai/gpt-4o-mini",
      "context_size": "file_only",
      "generation_strategy": "standard"
    },
    "workflow": "code_review"
  }
}